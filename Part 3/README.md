[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/VishalPallagani/LLMsforPlanningLab-AAAI24/blob/main/Part%203/LLM_types.ipynb)

# [Part 3] - Deep-Dive into LLMs                                                                              

## Overview
This tutorial introduces the fundamentals of three types of language models: Masked Language Models (MLM), Sequence-to-Sequence (Seq2Seq), and Causal Language Models (CLM), using the Hugging Face Transformers library.

## Prerequisites
- Basic understanding of Python programming.
- Familiarity with neural networks and NLP concepts.

## How to Run This Notebook
1. **Open in Google Colab**: Click on the link at the top of the notebook to open it in Google Colab.
2. **Install Dependencies**: Run the first code cell to install required Python packages.
3. **Runtime Setup**: Ensure you are using a Python environment with GPU support for better performance. In Google Colab, you can set this via `Runtime > Change runtime type > Hardware accelerator > GPU`.
4. **Run Each Cell**: Execute each cell in sequence by pressing `Shift + Enter`. Read the comments and instructions in each cell to understand the code and outputs.
5. **Experiment**: Feel free to modify the code or experiment with different pre-trained models.

## Sections in the Notebook
1. **Setup**: Installation and imports.
2. **Masked Language Modeling (MLM)**: See MLM in action using BERT.
3. **Seq2Seq Language Modeling**: Learn about Seq2Seq using models like T5.
4. **Causal Language Modeling (CLM)**: Generate text using GPT-2 or similar CLM.

## Support
For questions or issues, please raise an issue in the repository or contact the author.

## Acknowledgments
This tutorial was created using resources and tools from Hugging Face, Google Colab, and other open-source contributions.
